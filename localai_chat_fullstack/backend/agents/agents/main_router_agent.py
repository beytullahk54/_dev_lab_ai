from ..core.state import AgentState
from ..core.llm import llm
from langchain_core.messages import HumanMessage, SystemMessage

def main_router_agent(state: AgentState):
    """RESEPSÄ°YONÄ°ST: Soruyu Qwen3 ile analiz eder."""
    print(f"\nğŸ¤– Qwen3 Router: Ä°stek analiz ediliyor... ('{state['user_query']}')")
    
    system_prompt = """
    Sen bir yÃ¶nlendirme asistanÄ±sÄ±n. Gelen soruyu analiz et ve ÅŸu 3 kategoriden birini seÃ§:
    - "math": Matematiksel iÅŸlemler ve sayÄ±sal problemler.
    - "support" : YazÄ±lÄ±msal destek talepleri ve sorunlar iÃ§in buraya yÃ¶nlendir
    - 'it_legal': BiliÅŸim hukuku, KVKK, siber suÃ§lar, internet yasalarÄ±.
    - "legal": Hukuk, kanunlar ve sÃ¶zleÅŸmeler.
    - "greeting": Merhaba, nasÄ±lsÄ±n gibi gÃ¼nlÃ¼k sohbetler.
    - "vektor" : Åehir bilgileri iÃ§in buraya yÃ¶nlendir
    
    Sadece kategoriyi tek kelime olarak cevapla (Ã¶rn: math).
    """
    
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=state['user_query'])
    ])
    
    category = response.content.strip().lower()
    # BazÄ± yerel modeller fazla aÃ§Ä±klama yapabilir, sadece anahtar kelimeyi ayÄ±klayalÄ±m:
    if "it_legal" in category: category = "it_legal"
    elif "math" in category: category = "math"
    elif "legal" in category: category = "legal"
    elif "vektor" in category: category = "vektor"
    elif "support" in category: category = "support"
    else: category = "greeting"
    
    print(f"ğŸ”€ Karar: {category.upper()}")
    return {"intent": category}
