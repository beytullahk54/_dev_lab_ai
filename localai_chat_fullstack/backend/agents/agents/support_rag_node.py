import os
from ..core.llm import llm, llm_qwen1
from ..core.state import AgentState
from ..core.embedding_engine import text_to_vector
from ..core.qdrant import query_points

def support_rag_node(state: AgentState):
    """Support RAG AJANI: Destek sorularÄ±nÄ± Ã¶nceki cevaplara gÃ¶re mÃ¼ÅŸteriyi bilgilendirir."""
    print("ğŸ‘‹ Support AjanÄ± Ã‡alÄ±ÅŸÄ±yor...")
    array = query_points("test_collection_2", state['user_query']) 
    
    if not array:
        print("âš ï¸ VektÃ¶rde veri bulunamadÄ±.")
        return {"final_answer": "ÃœzgÃ¼nÃ¼m, veritabanÄ±mda bu konuyla ilgili bilgi bulamadÄ±m."}

    context = os.linesep.join(array)
    prompt = f"""
    Sen bir yazÄ±lÄ±m destek ajanÄ±sÄ±n.
    AÅŸaÄŸÄ±daki kurallara uyarsÄ±n
    1) Sen sana soru soran mÃ¼ÅŸteriye Ã¶nceki cevaplardan derleme yaparak Ã§Ã¶zÃ¼mÃ¼ verirsin.
    2) CevaplarÄ±nda mÃ¼ÅŸteri ismi vermezsin.
    3) Firma Ã¶zelinde bilgi vermezsin
    4) MÃ¼ÅŸterinin sorusuyla ilgili Ã§Ã¶zÃ¼m Ã¶nerisinde bulunursun 
    5) Maximum 5 6 paragraftan oluÅŸan cÃ¼mleler oluÅŸturursun
    6) Sadece aÅŸaÄŸÄ±da verilen iÃ§eriÄŸe baÄŸlÄ± kalÄ±rsÄ±n. Soru Konu alanÄ±ndaki soruyu buna gÃ¶re yanÄ±tlarsÄ±n
    
    Ä°Ã§erik
    ---
    {context}

    Soru/Konu: {state['user_query']}
    """

    response = llm_qwen1.invoke(prompt)
    return {"final_answer": response.content}
