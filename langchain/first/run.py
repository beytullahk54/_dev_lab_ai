import os
from typing import TypedDict, Literal
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_ollama import ChatOllama  # OpenAI yerine Ollama kullanÄ±yoruz

# --- 3. BÄ°LÄ°ÅÄ°M HUKUKU VERÄ° TABANI (RAG SÄ°MÃœLASYONU) ---
IT_LEGAL_DOCS = [
    "Madde 1: KVKK Madde 12 - Veri sorumlusu, kiÅŸisel verilerin gÃ¼venliÄŸini saÄŸlamak iÃ§in gerekli teknik tedbirleri almak zorundadÄ±r.",
    "Madde 2: TCK Madde 243 - BiliÅŸim sistemine yetkisiz giriÅŸ yapmanÄ±n cezasÄ± 1 yÄ±la kadar hapistir.",
    "Madde 3: 5651 SayÄ±lÄ± Kanun - Yer saÄŸlayÄ±cÄ±lar, kullanÄ±cÄ± iÃ§eriklerini Ã¶nceden denetlemekle yÃ¼kÃ¼mlÃ¼ deÄŸildir."
]

# --- 1. STATE (HAFIZA) ---
class AgentState(TypedDict):
    user_query: str
    final_answer: str
    intent: str

# --- 2. MODEL TANIMI (QWEN3:8B) ---
# BilgisayarÄ±nda Ollama aÃ§Ä±k olmalÄ± ve 'ollama pull qwen3:8b' yapmÄ±ÅŸ olmalÄ±sÄ±n.
llm = ChatOllama(
    model="qwen3:4b",
    temperature=0,  # Router iÅŸlemleri iÃ§in tutarlÄ±lÄ±k Ã¶nemli
    num_predict=1024
)

# --- 3. NODE'LAR (AJANLAR) ---

def main_router_agent(state: AgentState):
    """RESEPSÄ°YONÄ°ST: Soruyu Qwen3 ile analiz eder."""
    print(f"\nğŸ¤– Qwen3 Router: Ä°stek analiz ediliyor... ('{state['user_query']}')")
    
    system_prompt = """
    Sen bir yÃ¶nlendirme asistanÄ±sÄ±n. Gelen soruyu analiz et ve ÅŸu 3 kategoriden birini seÃ§:
    - "math": Matematiksel iÅŸlemler ve sayÄ±sal problemler.
    - 'it_legal': BiliÅŸim hukuku, KVKK, siber suÃ§lar, internet yasalarÄ±.
    - "legal": Hukuk, kanunlar ve sÃ¶zleÅŸmeler.
    - "greeting": Merhaba, nasÄ±lsÄ±n gibi gÃ¼nlÃ¼k sohbetler.
    
    Sadece kategoriyi tek kelime olarak cevapla (Ã¶rn: math).
    """
    
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=state['user_query'])
    ])
    
    category = response.content.strip().lower()
    # BazÄ± yerel modeller fazla aÃ§Ä±klama yapabilir, sadece anahtar kelimeyi ayÄ±klayalÄ±m:
    if "it_legal" in category: category = "it_legal"
    elif "math" in category: category = "math"
    elif "legal" in category: category = "legal"
    else: category = "greeting"
    
    print(f"ğŸ”€ Karar: {category.upper()}")
    return {"intent": category}

def it_legal_rag_node(state: AgentState):
    """RAG AJANI: Verilen 3 maddeye gÃ¶re cevap verir."""
    print("ğŸ–¥ï¸  BiliÅŸim Hukuku RAG AjanÄ± Ã§alÄ±ÅŸÄ±yor...")
    
    # Retrieval (Bilgi Getirme) aÅŸamasÄ±: 3 maddeyi context olarak birleÅŸtiriyoruz
    context = "\n".join(IT_LEGAL_DOCS)
    
    prompt = f"""
    Sen bir BiliÅŸim Hukuku uzmanÄ±sÄ±n. SADECE aÅŸaÄŸÄ±daki maddelere dayanarak cevap ver:
    {context}
    
    Soru: {state['user_query']}
    """
    
    response = llm.invoke(prompt)
    return {"final_answer": response.content}

def math_expert_node(state: AgentState):
    print("ğŸ§® Qwen3 Matematik UzmanÄ± Ã§alÄ±ÅŸÄ±yor...")
    response = llm.invoke(f"Bir matematik profesÃ¶rÃ¼ olarak Ã§Ã¶z: {state['user_query']}")
    return {"final_answer": response.content}

def legal_expert_node(state: AgentState):
    print("âš–ï¸  Qwen3 Hukuk UzmanÄ± Ã§alÄ±ÅŸÄ±yor...")
    response = llm.invoke(f"Bir avukat olarak TÃ¼rk Hukukuna gÃ¶re cevapla: {state['user_query']}")
    return {"final_answer": response.content}

def greeting_node(state: AgentState):
    print("ğŸ‘‹ Qwen3 KarÅŸÄ±lama Ekibi Ã§alÄ±ÅŸÄ±yor...")
    response = llm.invoke(f"NazikÃ§e selamla: {state['user_query']}")
    return {"final_answer": response.content}

# --- 4. GRAFÄ°K VE YÃ–NLENDÄ°RME MANTIÄI ---

def route_decision(state: AgentState) -> Literal["math", "legal", "greeting"]:
    return state["intent"]

workflow = StateGraph(AgentState)

workflow.add_node("main_agent", main_router_agent)
workflow.add_node("it_legal_expert", it_legal_rag_node) # Yeni RAG Node
workflow.add_node("math_expert", math_expert_node)
workflow.add_node("legal_expert", legal_expert_node)
workflow.add_node("greeting_expert", greeting_node)

workflow.set_entry_point("main_agent")

workflow.add_conditional_edges(
    "main_agent",
    route_decision,
    {
        "math": "math_expert",
        "it_legal": "it_legal_expert",
        "legal": "legal_expert",
        "greeting": "greeting_expert"
    }
)

workflow.add_edge("it_legal_expert", END)
workflow.add_edge("math_expert", END)
workflow.add_edge("legal_expert", END)
workflow.add_edge("greeting_expert", END)

app = workflow.compile()

# --- 5. Ã‡ALIÅTIRMA ---
def start_chat():
    print("\n" + "="*50)
    print("ğŸš€ Qwen3 Multi-Agent Sistemi BaÅŸlatÄ±ldÄ± (2026)")
    print("ğŸ¤– Departmanlar: Matematik, Genel Hukuk, BiliÅŸim Hukuku")
    print("ğŸ’¡ Ã‡Ä±kmak iÃ§in 'exit' veya 'quit' yazabilirsin.")
    print("="*50)

    while True:
        user_input = input("\nğŸ‘¤ Siz: ")
        
        if user_input.lower() in ["exit", "quit", "Ã§Ä±kÄ±ÅŸ"]:
            print("ğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere!")
            break

        # AjanlarÄ± Ã§alÄ±ÅŸtÄ±r
        print("â³ Ä°ÅŸleniyor...")
        result = app.invoke({"user_query": user_input, "intent": "", "final_answer": ""})
        
        # Sonucu Estetik BastÄ±r
        print(f"\nğŸ“‚ [Departman: {result['intent'].upper()}]")
        print(f"ğŸ¤– Asistan: {result['final_answer']}")
        print("-" * 30)

if __name__ == "__main__":
    start_chat()