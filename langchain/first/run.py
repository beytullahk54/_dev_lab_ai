import os
from typing import TypedDict, Literal
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_ollama import ChatOllama  # OpenAI yerine Ollama kullanÄ±yoruz

# --- 1. STATE (HAFIZA) ---
class AgentState(TypedDict):
    user_query: str
    final_answer: str
    intent: str

# --- 2. MODEL TANIMI (QWEN3:8B) ---
# BilgisayarÄ±nda Ollama aÃ§Ä±k olmalÄ± ve 'ollama pull qwen3:8b' yapmÄ±ÅŸ olmalÄ±sÄ±n.
llm = ChatOllama(
    model="gemma3:1b",
    temperature=0,  # Router iÅŸlemleri iÃ§in tutarlÄ±lÄ±k Ã¶nemli
    num_predict=1024
)

# --- 3. NODE'LAR (AJANLAR) ---

def main_router_agent(state: AgentState):
    """RESEPSÄ°YONÄ°ST: Soruyu Qwen3 ile analiz eder."""
    print(f"\nðŸ¤– Qwen3 Router: Ä°stek analiz ediliyor... ('{state['user_query']}')")
    
    system_prompt = """
    Sen bir yÃ¶nlendirme asistanÄ±sÄ±n. Gelen soruyu analiz et ve ÅŸu 3 kategoriden birini seÃ§:
    - "math": Matematiksel iÅŸlemler ve sayÄ±sal problemler.
    - "legal": Hukuk, kanunlar ve sÃ¶zleÅŸmeler.
    - "greeting": Merhaba, nasÄ±lsÄ±n gibi gÃ¼nlÃ¼k sohbetler.
    
    Sadece kategoriyi tek kelime olarak cevapla (Ã¶rn: math).
    """
    
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=state['user_query'])
    ])
    
    category = response.content.strip().lower()
    # BazÄ± yerel modeller fazla aÃ§Ä±klama yapabilir, sadece anahtar kelimeyi ayÄ±klayalÄ±m:
    if "math" in category: category = "math"
    elif "legal" in category: category = "legal"
    else: category = "greeting"
    
    print(f"ðŸ”€ Karar: {category.upper()}")
    return {"intent": category}

def math_expert_node(state: AgentState):
    print("ðŸ§® Qwen3 Matematik UzmanÄ± Ã§alÄ±ÅŸÄ±yor...")
    response = llm.invoke(f"Bir matematik profesÃ¶rÃ¼ olarak Ã§Ã¶z: {state['user_query']}")
    return {"final_answer": response.content}

def legal_expert_node(state: AgentState):
    print("âš–ï¸  Qwen3 Hukuk UzmanÄ± Ã§alÄ±ÅŸÄ±yor...")
    response = llm.invoke(f"Bir avukat olarak TÃ¼rk Hukukuna gÃ¶re cevapla: {state['user_query']}")
    return {"final_answer": response.content}

def greeting_node(state: AgentState):
    print("ðŸ‘‹ Qwen3 KarÅŸÄ±lama Ekibi Ã§alÄ±ÅŸÄ±yor...")
    response = llm.invoke(f"NazikÃ§e selamla: {state['user_query']}")
    return {"final_answer": response.content}

# --- 4. GRAFÄ°K VE YÃ–NLENDÄ°RME MANTIÄžI ---

def route_decision(state: AgentState) -> Literal["math", "legal", "greeting"]:
    return state["intent"]

workflow = StateGraph(AgentState)

workflow.add_node("main_agent", main_router_agent)
workflow.add_node("math_expert", math_expert_node)
workflow.add_node("legal_expert", legal_expert_node)
workflow.add_node("greeting_expert", greeting_node)

workflow.set_entry_point("main_agent")

workflow.add_conditional_edges(
    "main_agent",
    route_decision,
    {
        "math": "math_expert",
        "legal": "legal_expert",
        "greeting": "greeting_expert"
    }
)

workflow.add_edge("math_expert", END)
workflow.add_edge("legal_expert", END)
workflow.add_edge("greeting_expert", END)

app = workflow.compile()

# --- 5. Ã‡ALIÅžTIRMA ---
if __name__ == "__main__":
    soru = "Mirastaki saklÄ± pay oranlarÄ± nedir?"
    result = app.invoke({"user_query": soru, "intent": "", "final_answer": ""})
    print(f"\nðŸ“© Qwen3 YanÄ±tÄ±:\n{result['final_answer']}")