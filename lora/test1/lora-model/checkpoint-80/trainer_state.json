{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.125,
      "grad_norm": 1.882746934890747,
      "learning_rate": 0.0002,
      "loss": 3.0207629203796387,
      "step": 1
    },
    {
      "epoch": 0.25,
      "grad_norm": 14145.5556640625,
      "learning_rate": 0.00019750000000000003,
      "loss": 2.0932199954986572,
      "step": 2
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.4916300773620605,
      "learning_rate": 0.000195,
      "loss": 2.3040778636932373,
      "step": 3
    },
    {
      "epoch": 0.5,
      "grad_norm": 18.268638610839844,
      "learning_rate": 0.00019250000000000002,
      "loss": 1.8676583766937256,
      "step": 4
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.2429733276367188,
      "learning_rate": 0.00019,
      "loss": 2.272329807281494,
      "step": 5
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.6816987991333008,
      "learning_rate": 0.0001875,
      "loss": 1.7302110195159912,
      "step": 6
    },
    {
      "epoch": 0.875,
      "grad_norm": 3784.087890625,
      "learning_rate": 0.00018500000000000002,
      "loss": 2.862687826156616,
      "step": 7
    },
    {
      "epoch": 1.0,
      "grad_norm": 11280.7470703125,
      "learning_rate": 0.0001825,
      "loss": 1.4236271381378174,
      "step": 8
    },
    {
      "epoch": 1.125,
      "grad_norm": 1.5428743362426758,
      "learning_rate": 0.00018,
      "loss": 1.6576865911483765,
      "step": 9
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.8194248676300049,
      "learning_rate": 0.0001775,
      "loss": 1.674794316291809,
      "step": 10
    },
    {
      "epoch": 1.375,
      "grad_norm": 103.10638427734375,
      "learning_rate": 0.000175,
      "loss": 2.1549954414367676,
      "step": 11
    },
    {
      "epoch": 1.5,
      "grad_norm": 6195.7509765625,
      "learning_rate": 0.00017250000000000002,
      "loss": 2.046013355255127,
      "step": 12
    },
    {
      "epoch": 1.625,
      "grad_norm": 4914.12158203125,
      "learning_rate": 0.00017,
      "loss": 2.785491943359375,
      "step": 13
    },
    {
      "epoch": 1.75,
      "grad_norm": 55.43503189086914,
      "learning_rate": 0.0001675,
      "loss": 1.8754639625549316,
      "step": 14
    },
    {
      "epoch": 1.875,
      "grad_norm": 5462.21533203125,
      "learning_rate": 0.000165,
      "loss": 2.593926429748535,
      "step": 15
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.841974139213562,
      "learning_rate": 0.00016250000000000002,
      "loss": 2.4041333198547363,
      "step": 16
    },
    {
      "epoch": 2.125,
      "grad_norm": 1.8650352954864502,
      "learning_rate": 0.00016,
      "loss": 2.5372314453125,
      "step": 17
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.7862322330474854,
      "learning_rate": 0.0001575,
      "loss": 2.241048574447632,
      "step": 18
    },
    {
      "epoch": 2.375,
      "grad_norm": 13843.6455078125,
      "learning_rate": 0.000155,
      "loss": 2.1596627235412598,
      "step": 19
    },
    {
      "epoch": 2.5,
      "grad_norm": 27.534055709838867,
      "learning_rate": 0.0001525,
      "loss": 2.1975953578948975,
      "step": 20
    },
    {
      "epoch": 2.625,
      "grad_norm": 2.3624088764190674,
      "learning_rate": 0.00015000000000000001,
      "loss": 1.5119253396987915,
      "step": 21
    },
    {
      "epoch": 2.75,
      "grad_norm": 8637.240234375,
      "learning_rate": 0.0001475,
      "loss": 1.8004316091537476,
      "step": 22
    },
    {
      "epoch": 2.875,
      "grad_norm": 3.8231611251831055,
      "learning_rate": 0.000145,
      "loss": 2.1841824054718018,
      "step": 23
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.0283641815185547,
      "learning_rate": 0.00014250000000000002,
      "loss": 1.4824415445327759,
      "step": 24
    },
    {
      "epoch": 3.125,
      "grad_norm": 4.07166051864624,
      "learning_rate": 0.00014,
      "loss": 2.2447943687438965,
      "step": 25
    },
    {
      "epoch": 3.25,
      "grad_norm": 50.08842849731445,
      "learning_rate": 0.0001375,
      "loss": 2.1378819942474365,
      "step": 26
    },
    {
      "epoch": 3.375,
      "grad_norm": 2.1069703102111816,
      "learning_rate": 0.00013500000000000003,
      "loss": 2.249793291091919,
      "step": 27
    },
    {
      "epoch": 3.5,
      "grad_norm": 23380.591796875,
      "learning_rate": 0.0001325,
      "loss": 2.586583375930786,
      "step": 28
    },
    {
      "epoch": 3.625,
      "grad_norm": 2.427968978881836,
      "learning_rate": 0.00013000000000000002,
      "loss": 1.3323873281478882,
      "step": 29
    },
    {
      "epoch": 3.75,
      "grad_norm": 26475.484375,
      "learning_rate": 0.0001275,
      "loss": 1.9373650550842285,
      "step": 30
    },
    {
      "epoch": 3.875,
      "grad_norm": 2.260080337524414,
      "learning_rate": 0.000125,
      "loss": 1.379467248916626,
      "step": 31
    },
    {
      "epoch": 4.0,
      "grad_norm": 4.440643310546875,
      "learning_rate": 0.00012250000000000002,
      "loss": 1.5850787162780762,
      "step": 32
    },
    {
      "epoch": 4.125,
      "grad_norm": 2.1982929706573486,
      "learning_rate": 0.00012,
      "loss": 2.012338638305664,
      "step": 33
    },
    {
      "epoch": 4.25,
      "grad_norm": 156.85476684570312,
      "learning_rate": 0.00011750000000000001,
      "loss": 1.6825703382492065,
      "step": 34
    },
    {
      "epoch": 4.375,
      "grad_norm": 44.47185134887695,
      "learning_rate": 0.00011499999999999999,
      "loss": 2.1475744247436523,
      "step": 35
    },
    {
      "epoch": 4.5,
      "grad_norm": 9923.3173828125,
      "learning_rate": 0.00011250000000000001,
      "loss": 2.42103910446167,
      "step": 36
    },
    {
      "epoch": 4.625,
      "grad_norm": 2.4356606006622314,
      "learning_rate": 0.00011000000000000002,
      "loss": 1.3901617527008057,
      "step": 37
    },
    {
      "epoch": 4.75,
      "grad_norm": 2.0596232414245605,
      "learning_rate": 0.0001075,
      "loss": 1.4369561672210693,
      "step": 38
    },
    {
      "epoch": 4.875,
      "grad_norm": 9251.36328125,
      "learning_rate": 0.000105,
      "loss": 2.024522066116333,
      "step": 39
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.570709705352783,
      "learning_rate": 0.0001025,
      "loss": 2.087524652481079,
      "step": 40
    },
    {
      "epoch": 5.125,
      "grad_norm": 59.626338958740234,
      "learning_rate": 0.0001,
      "loss": 2.1201748847961426,
      "step": 41
    },
    {
      "epoch": 5.25,
      "grad_norm": 3.2664804458618164,
      "learning_rate": 9.75e-05,
      "loss": 1.376420021057129,
      "step": 42
    },
    {
      "epoch": 5.375,
      "grad_norm": 65.32687377929688,
      "learning_rate": 9.5e-05,
      "loss": 1.7171634435653687,
      "step": 43
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.1650161743164062,
      "learning_rate": 9.250000000000001e-05,
      "loss": 2.302844762802124,
      "step": 44
    },
    {
      "epoch": 5.625,
      "grad_norm": 35599.09375,
      "learning_rate": 9e-05,
      "loss": 2.300018310546875,
      "step": 45
    },
    {
      "epoch": 5.75,
      "grad_norm": 11455.5673828125,
      "learning_rate": 8.75e-05,
      "loss": 1.8761475086212158,
      "step": 46
    },
    {
      "epoch": 5.875,
      "grad_norm": 4.41768217086792,
      "learning_rate": 8.5e-05,
      "loss": 1.0713069438934326,
      "step": 47
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.3304812908172607,
      "learning_rate": 8.25e-05,
      "loss": 1.5076967477798462,
      "step": 48
    },
    {
      "epoch": 6.125,
      "grad_norm": 90.25564575195312,
      "learning_rate": 8e-05,
      "loss": 2.078223705291748,
      "step": 49
    },
    {
      "epoch": 6.25,
      "grad_norm": 224.4033966064453,
      "learning_rate": 7.75e-05,
      "loss": 2.194810152053833,
      "step": 50
    },
    {
      "epoch": 6.375,
      "grad_norm": 3.229501485824585,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.9718742370605469,
      "step": 51
    },
    {
      "epoch": 6.5,
      "grad_norm": 41174.62890625,
      "learning_rate": 7.25e-05,
      "loss": 1.7786519527435303,
      "step": 52
    },
    {
      "epoch": 6.625,
      "grad_norm": 2.2973105907440186,
      "learning_rate": 7e-05,
      "loss": 1.7408746480941772,
      "step": 53
    },
    {
      "epoch": 6.75,
      "grad_norm": 3.162209987640381,
      "learning_rate": 6.750000000000001e-05,
      "loss": 1.1506669521331787,
      "step": 54
    },
    {
      "epoch": 6.875,
      "grad_norm": 2.8047091960906982,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.8883268237113953,
      "step": 55
    },
    {
      "epoch": 7.0,
      "grad_norm": 3.6535825729370117,
      "learning_rate": 6.25e-05,
      "loss": 2.495286226272583,
      "step": 56
    },
    {
      "epoch": 7.125,
      "grad_norm": 16462.1953125,
      "learning_rate": 6e-05,
      "loss": 1.708556890487671,
      "step": 57
    },
    {
      "epoch": 7.25,
      "grad_norm": 18088.4140625,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 2.266265630722046,
      "step": 58
    },
    {
      "epoch": 7.375,
      "grad_norm": 16588.8828125,
      "learning_rate": 5.500000000000001e-05,
      "loss": 2.0697314739227295,
      "step": 59
    },
    {
      "epoch": 7.5,
      "grad_norm": 94.17878723144531,
      "learning_rate": 5.25e-05,
      "loss": 1.9235976934432983,
      "step": 60
    },
    {
      "epoch": 7.625,
      "grad_norm": 2.8491475582122803,
      "learning_rate": 5e-05,
      "loss": 1.8546184301376343,
      "step": 61
    },
    {
      "epoch": 7.75,
      "grad_norm": 3.611579656600952,
      "learning_rate": 4.75e-05,
      "loss": 1.0375114679336548,
      "step": 62
    },
    {
      "epoch": 7.875,
      "grad_norm": 2.202720880508423,
      "learning_rate": 4.5e-05,
      "loss": 1.4497942924499512,
      "step": 63
    },
    {
      "epoch": 8.0,
      "grad_norm": 5.612843036651611,
      "learning_rate": 4.25e-05,
      "loss": 1.2375608682632446,
      "step": 64
    },
    {
      "epoch": 8.125,
      "grad_norm": 3.072526693344116,
      "learning_rate": 4e-05,
      "loss": 1.1706867218017578,
      "step": 65
    },
    {
      "epoch": 8.25,
      "grad_norm": 65503.1171875,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 1.7427681684494019,
      "step": 66
    },
    {
      "epoch": 8.375,
      "grad_norm": 2.4639906883239746,
      "learning_rate": 3.5e-05,
      "loss": 1.2057827711105347,
      "step": 67
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.7966156005859375,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 1.023320198059082,
      "step": 68
    },
    {
      "epoch": 8.625,
      "grad_norm": 22217.83203125,
      "learning_rate": 3e-05,
      "loss": 2.315044403076172,
      "step": 69
    },
    {
      "epoch": 8.75,
      "grad_norm": 3.3799448013305664,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 2.4091856479644775,
      "step": 70
    },
    {
      "epoch": 8.875,
      "grad_norm": 92.66864013671875,
      "learning_rate": 2.5e-05,
      "loss": 1.9145443439483643,
      "step": 71
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.9344522953033447,
      "learning_rate": 2.25e-05,
      "loss": 1.807402491569519,
      "step": 72
    },
    {
      "epoch": 9.125,
      "grad_norm": 111.08527374267578,
      "learning_rate": 2e-05,
      "loss": 2.0885372161865234,
      "step": 73
    },
    {
      "epoch": 9.25,
      "grad_norm": 19663.2578125,
      "learning_rate": 1.75e-05,
      "loss": 2.4621386528015137,
      "step": 74
    },
    {
      "epoch": 9.375,
      "grad_norm": 2.5313093662261963,
      "learning_rate": 1.5e-05,
      "loss": 1.5015037059783936,
      "step": 75
    },
    {
      "epoch": 9.5,
      "grad_norm": 2.9444406032562256,
      "learning_rate": 1.25e-05,
      "loss": 1.1853561401367188,
      "step": 76
    },
    {
      "epoch": 9.625,
      "grad_norm": 23668.12890625,
      "learning_rate": 1e-05,
      "loss": 1.6990777254104614,
      "step": 77
    },
    {
      "epoch": 9.75,
      "grad_norm": 2.5132858753204346,
      "learning_rate": 7.5e-06,
      "loss": 0.8095529079437256,
      "step": 78
    },
    {
      "epoch": 9.875,
      "grad_norm": 351.8915710449219,
      "learning_rate": 5e-06,
      "loss": 2.1166622638702393,
      "step": 79
    },
    {
      "epoch": 10.0,
      "grad_norm": 5.7328715324401855,
      "learning_rate": 2.5e-06,
      "loss": 1.1834194660186768,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 80,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 45692849077248.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
