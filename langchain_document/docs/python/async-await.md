# Ders 4: Async / Await

> **Laravel karÅŸÄ±lÄ±ÄŸÄ±:** Laravel Queue ile bir iÅŸi arka plana atarsÄ±n, cevabÄ± beklemezsin. Python'da `async/await` ise **beklersin** ama aynÄ± anda birden fazla iÅŸi sÃ¼rdÃ¼rÃ¼rsÃ¼n â€” Laravel'deki `Http::async()->get()` + `Promise` gibi.

---

## ğŸ¤” Neden Async?

LLM API'leri (OpenAI, Anthropic) network Ã§aÄŸrÄ±sÄ±dÄ±r. Async ile bu Ã§aÄŸrÄ± yapÄ±lÄ±rken CPU boÅŸ kalmaz, baÅŸka iÅŸler Ã§alÄ±ÅŸÄ±r.

```
Sync (normal):    [Ä°stek 1] --- bekliyorum --- [cevap 1] [Ä°stek 2] --- bekliyorum --- [cevap 2]
Async:            [Ä°stek 1] [Ä°stek 2]           [cevap 1] [cevap 2]
                  â†‘ Ä°kisi aynÄ± anda gÃ¶nderildi!
```

---

## ğŸ”¥ Temel KullanÄ±m

```python
import asyncio

# async fonksiyon tanÄ±mÄ±
async def selam_ver(ad: str) -> str:
    await asyncio.sleep(1)  # 1 saniye bekle (LLM Ã§aÄŸrÄ±sÄ± simÃ¼lasyonu)
    return f"Merhaba, {ad}!"

# async fonksiyonu Ã§alÄ±ÅŸtÄ±r
async def main():
    sonuc = await selam_ver("Ahmet")
    print(sonuc)  # -> Merhaba, Ahmet!

# asyncio.run() ile baÅŸlat â€” PHP'deki index.php gibi giriÅŸ noktasÄ±
asyncio.run(main())
```

---

## âš¡ Paralel Ã‡alÄ±ÅŸtÄ±rma â€” asyncio.gather()

```python
import asyncio

async def llm_cagir(soru: str, model: str) -> str:
    """LLM Ã§aÄŸrÄ±sÄ± simÃ¼lasyonu â€” farklÄ± modeller farklÄ± sÃ¼re alÄ±r"""
    await asyncio.sleep(2)  # Network gecikmesi simÃ¼lasyonu
    return f"[{model}] Cevap: {soru}"

async def main():
    # SÄ±ralÄ± â€” toplamda 4 saniye sÃ¼rer
    # cevap1 = await llm_cagir("Soru 1", "gpt-4")
    # cevap2 = await llm_cagir("Soru 2", "claude")

    # Paralel â€” sadece 2 saniye sÃ¼rer! (en yavaÅŸ kadar)
    cevap1, cevap2 = await asyncio.gather(
        llm_cagir("Python nedir?", "gpt-4"),
        llm_cagir("LangGraph nedir?", "claude"),
    )

    print(cevap1)  # -> [gpt-4] Cevap: Python nedir?
    print(cevap2)  # -> [claude] Cevap: LangGraph nedir?

asyncio.run(main())
```

---

## ğŸ”¥ LangGraph'ta Async Node

LangGraph node'larÄ± async olabilir ve olmalÄ± â€” Ã§Ã¼nkÃ¼ LLM Ã§aÄŸrÄ±larÄ± async:

```python
import asyncio
from typing import TypedDict, List
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage

class AgentState(TypedDict):
    messages: List[dict]
    user_input: str
    response: str

# Async node â€” 'async def' ile tanÄ±mlanÄ±r
async def llm_node(state: AgentState) -> dict:
    """LLM'e sorar ve cevabÄ± state'e yazar"""

    llm = ChatOpenAI(model="gpt-4", temperature=0.7)

    # await ile LLM Ã§aÄŸrÄ±sÄ± â€” cevap gelene kadar bekle
    response = await llm.ainvoke([
        HumanMessage(content=state["user_input"])
    ])

    return {"response": response.content}

# Test (API key olmadan simÃ¼lasyon)
async def test_node():
    state: AgentState = {
        "messages": [],
        "user_input": "Python Ã¶ÄŸrenmek istiyorum",
        "response": "",
    }

    # GerÃ§ekte LLM Ã§aÄŸrÄ±sÄ± yapÄ±lÄ±r
    # result = await llm_node(state)
    print("Async node Ã§alÄ±ÅŸÄ±yor...")

asyncio.run(test_node())
```

---

## ğŸ§© Async Context Manager â€” `async with`

```python
import asyncio
import aiohttp  # pip install aiohttp

async def api_cagir(url: str) -> dict:
    """HTTP isteÄŸi â€” requests yerine aiohttp kullan (async iÃ§in)"""
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            return await response.json()

# Birden fazla API Ã§aÄŸrÄ±sÄ± paralel
async def coklu_api():
    urls = [
        "https://api.github.com/repos/langchain-ai/langgraph",
        "https://api.github.com/repos/langchain-ai/langchain",
    ]

    sonuclar = await asyncio.gather(
        *[api_cagir(url) for url in urls]
    )

    for sonuc in sonuclar:
        print(f"Repo: {sonuc.get('name', 'N/A')}, Stars: {sonuc.get('stargazers_count', 0)}")

# asyncio.run(coklu_api())  # Ä°nternet baÄŸlantÄ±sÄ± gerekir
```

---

## ğŸ”„ Async Generator â€” Streaming

LLM cevabÄ± stream olarak almak iÃ§in:

```python
import asyncio
from typing import AsyncGenerator

async def llm_stream(prompt: str) -> AsyncGenerator[str, None]:
    """LLM'den kelime kelime cevap al â€” streaming"""
    kelimeler = ["Python", " Ã§ok", " gÃ¼Ã§lÃ¼", " bir", " dil!"]
    for kelime in kelimeler:
        await asyncio.sleep(0.3)  # Stream gecikmesi simÃ¼lasyonu
        yield kelime

async def streaming_ornek():
    async for parca in llm_stream("Python nedir?"):
        print(parca, end="", flush=True)  # AnlÄ±k yazdÄ±r
    print()  # Yeni satÄ±r

asyncio.run(streaming_ornek())
# -> Python Ã§ok gÃ¼Ã§lÃ¼ bir dil! (kelime kelime gelir)
```

---

## ğŸ”¥ LangGraph Async Graph

```python
import asyncio
from typing import TypedDict
from langgraph.graph import StateGraph, END

class State(TypedDict):
    user_input: str
    step1_result: str
    step2_result: str

async def node_1(state: State) -> dict:
    await asyncio.sleep(0.1)  # LLM Ã§aÄŸrÄ±sÄ± simÃ¼lasyonu
    return {"step1_result": f"Ä°ÅŸlendi: {state['user_input']}"}

async def node_2(state: State) -> dict:
    await asyncio.sleep(0.1)
    return {"step2_result": f"ZenginleÅŸtirildi: {state['step1_result']}"}

# Graph kur
graph = StateGraph(State)
graph.add_node("node1", node_1)
graph.add_node("node2", node_2)
graph.set_entry_point("node1")
graph.add_edge("node1", "node2")
graph.add_edge("node2", END)

app = graph.compile()

# Async Ã§alÄ±ÅŸtÄ±r
async def main():
    result = await app.ainvoke({   # ainvoke = async invoke
        "user_input": "Merhaba",
        "step1_result": "",
        "step2_result": "",
    })
    print(result["step2_result"])
    # -> ZenginleÅŸtirildi: Ä°ÅŸlendi: Merhaba

asyncio.run(main())
```

---

## âš ï¸ SÄ±k YapÄ±lan Hatalar

**Hata:** `RuntimeWarning: coroutine 'xyz' was never awaited`

```python
async def selam() -> str:
    return "Merhaba"

# YANLIÅ â€” await unutulmuÅŸ
# sonuc = selam()      # Coroutine object, string deÄŸil!

# DOÄRU
async def main():
    sonuc = await selam()   # await ile Ã§aÄŸÄ±r
    print(sonuc)

asyncio.run(main())
```

> ğŸ”´ **Laravel analogisi:** `dispatch(new MyJob())` yerine `new MyJob()` yazÄ±p unutmak gibi â€” iÅŸ hiÃ§ Ã§alÄ±ÅŸmaz.

**Hata:** `SyntaxError: 'await' outside async function`

```python
# YANLIÅ â€” normal fonksiyon iÃ§inde await kullanÄ±lamaz
def normal_fonksiyon():
    sonuc = await baska_async()  # SyntaxError!

# DOÄRU â€” async def kullan
async def async_fonksiyon():
    sonuc = await baska_async()  # OK
```

---

## ğŸ¯ GÃ¶rev

AÅŸaÄŸÄ±daki async LangGraph node'unu tamamla:

```python
import asyncio
from typing import TypedDict, List

class ChatState(TypedDict):
    user_input: str
    agent_responses: List[str]   # Birden fazla agent cevabÄ±

# Bu fonksiyon 3 farklÄ± "agent"Ä± (simulate) paralel Ã§alÄ±ÅŸtÄ±rmalÄ±
# ve cevaplarÄ±nÄ± agent_responses listesine eklemeli
async def paralel_agent_node(state: ChatState) -> dict:
    ???
```

<details>
<summary>ğŸ’¡ Ã‡Ã¶zÃ¼mÃ¼ gÃ¶ster</summary>

```python
import asyncio
from typing import TypedDict, List

class ChatState(TypedDict):
    user_input: str
    agent_responses: List[str]

async def agent_calistir(agent_adi: str, soru: str) -> str:
    """Tek bir agent'Ä± simÃ¼le et"""
    await asyncio.sleep(0.5)  # Her agent yarÄ±m saniye sÃ¼rer
    return f"[{agent_adi}]: '{soru}' sorusuna cevabÄ±m hazÄ±r."

async def paralel_agent_node(state: ChatState) -> dict:
    # 3 agent'Ä± paralel Ã§alÄ±ÅŸtÄ±r
    cevaplar = await asyncio.gather(
        agent_calistir("HukukAgent", state["user_input"]),
        agent_calistir("MatematikAgent", state["user_input"]),
        agent_calistir("GenelAgent", state["user_input"]),
    )

    return {"agent_responses": list(cevaplar)}

# Test
async def main():
    sonuc = await paralel_agent_node({
        "user_input": "YardÄ±m lazÄ±m",
        "agent_responses": [],
    })
    for cevap in sonuc["agent_responses"]:
        print(cevap)

asyncio.run(main())
```

</details>

---

**Ã–nceki ders:** [Fonksiyonlar & Decorator â†](./functions-decorator) | **Sonraki ders:** [Class YapÄ±sÄ± â†’](./class-yapisi)
