# Daha FazlasÄ± Var

Bu dokÃ¼mantasyonda multi-agent mimarinin temellerini Ã¶ÄŸrendik. Ama ekosistem Ã§ok daha geniÅŸ. Bu sayfada **henÃ¼z deÄŸinmediÄŸimiz** ama bilmeni istediÄŸimiz kavramlara kÄ±saca bakÄ±yoruz.

---

## ğŸ”€ LangGraph â€” KeÅŸfetmediÄŸimiz Ã–zellikler

### 1. Send API â€” Paralel Node Ã‡alÄ±ÅŸtÄ±rma

Åimdiye kadar node'lar **sÄ±rayla** Ã§alÄ±ÅŸtÄ±. `Send` ile aynÄ± anda **paralel** Ã§alÄ±ÅŸtÄ±rabilirsin:

```python
from langgraph.types import Send

def dagit(state: SinifState):
    # 3 ders ajanÄ±nÄ± aynÄ± anda baÅŸlat
    return [
        Send("matematik", state),
        Send("fizik", state),
        Send("kimya", state),
    ]

workflow.add_conditional_edges("__start__", dagit)
```

ÃœÃ§ ajan **eÅŸ zamanlÄ±** Ã§alÄ±ÅŸÄ±r â€” bÃ¼yÃ¼k sistemlerde ciddi hÄ±z kazancÄ± saÄŸlar.

---

### 2. Subgraph â€” Graf Ä°Ã§inde Graf

KarmaÅŸÄ±k sistemleri alt graflara bÃ¶lebilirsin:

```python
# KÃ¼Ã§Ã¼k bir alt graf
muhasebe_workflow = StateGraph(MuhasebeState)
muhasebe_workflow.add_node(...)
muhasebe_app = muhasebe_workflow.compile()

# Ana grafa entegre et
ana_workflow = StateGraph(AnaState)
ana_workflow.add_node("muhasebe", muhasebe_app)  # â† subgraph
```

Her ekip kendi alt grafÄ±nÄ± geliÅŸtirir, ana sistem bunlarÄ± bir araya getirir.

---

### 3. Human-in-the-Loop â€” Ä°nsan OnayÄ±

Kritik bir adÄ±mdan Ã¶nce sistemi durdur, insan onayÄ± al:

```python
app = workflow.compile(
    interrupt_before=["odeme_node"]  # Ã¶deme yapmadan Ã¶nce dur
)

# Ã‡alÄ±ÅŸtÄ±r â€” odeme_node'a gelince durur
app.invoke(state, config={"configurable": {"thread_id": "1"}})

# Ä°nsan onayladÄ± mÄ±? â†’ devam et
app.invoke(None, config={"configurable": {"thread_id": "1"}})
```

KullanÄ±m alanÄ±: Para transferi, e-posta gÃ¶nderme, Ã¼retim ortamÄ±nda deploy.

---

### 4. Streaming â€” AdÄ±m AdÄ±m AkÄ±ÅŸ

YanÄ±tÄ± kelime kelime al, kullanÄ±cÄ±ya anlÄ±k gÃ¶ster:

```python
# Node bazlÄ± stream
for event in app.stream(initial_state, stream_mode="updates"):
    node_adi = list(event.keys())[0]
    print(f"[{node_adi}] tamamlandÄ±")

# Token bazlÄ± stream (LLM yanÄ±tÄ±nÄ± kelime kelime)
async for chunk in llm.astream([HumanMessage(content="Merhaba")]):
    print(chunk.content, end="", flush=True)
```

---

### 5. Persistence â€” KonuÅŸma GeÃ§miÅŸi

Graf durumunu kaydet, konuÅŸmayÄ± kesip devam ettir:

```python
from langgraph.checkpoint.sqlite import SqliteSaver

# SQLite'a kaydet
with SqliteSaver.from_conn_string("chat_history.db") as checkpointer:
    app = workflow.compile(checkpointer=checkpointer)

    # thread_id ile konuÅŸma kimliÄŸi ver
    config = {"configurable": {"thread_id": "kullanici_42"}}

    # Ä°lk mesaj
    app.invoke({"messages": [HumanMessage("Merhaba")]}, config)

    # Saatler sonra â€” kaldÄ±ÄŸÄ± yerden devam eder
    app.invoke({"messages": [HumanMessage("Devam edelim mi?")]}, config)
```

---

### 6. LangGraph Studio

LangGraph'Ä±n gÃ¶rsel IDE'si â€” grafÄ± Ã§alÄ±ÅŸtÄ±r, debug et, state'i izle:

```bash
pip install langgraph-cli
langgraph dev
```

TarayÄ±cÄ±da gerÃ§ek zamanlÄ± olarak:
- Graf gÃ¶rselini izle
- Her node'un state'ini gÃ¶r
- AdÄ±m adÄ±m ilerle
- HatalarÄ± yakala

> LangGraph Studio iÃ§in `langgraph.json` config dosyasÄ± gerekir.

---

## ğŸ”­ LangSmith â€” GÃ¶zlemlenebilirlik

LangSmith, LangChain uygulamalarÄ±nÄ± **izlemek, debug etmek ve deÄŸerlendirmek** iÃ§in Anthropic'in resmi platformudur.

### Kurulum

```bash
pip install langsmith
```

```python
import os
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "ls__..."
os.environ["LANGCHAIN_PROJECT"] = "sinif-gecme-agenti"
```

Bu 3 satÄ±rÄ± ekledikten sonra **kod deÄŸiÅŸikliÄŸi yapmadan** her Ã§aÄŸrÄ± otomatik loglanÄ±r.

---

### 1. Tracing â€” Ä°z SÃ¼rme

Her LLM Ã§aÄŸrÄ±sÄ±nÄ±, her node'u, her token'Ä± kayÄ±t altÄ±na alÄ±r:

```
Run: sinif_gecme_agenti
â”œâ”€â”€ matematik_agent       âœ…  42ms
â”œâ”€â”€ fizik_agent           âœ…  38ms
â”œâ”€â”€ kimya_agent           âœ…  41ms
â”œâ”€â”€ karar_agent           âœ…  12ms
â””â”€â”€ kaldi_node            âœ…   5ms

Toplam sÃ¼re: 138ms  |  Toplam token: 847  |  Maliyet: $0.0012
```

LangSmith'in dashboard'unda her ÅŸeyi gÃ¶rebilirsin.

---

### 2. Evaluator â€” Otomatik DeÄŸerlendirme

LLM yanÄ±tlarÄ±nÄ± otomatik puanla:

```python
from langsmith.evaluation import evaluate, LangChainStringEvaluator

# Test verisi
dataset = [
    {"input": "2+2", "expected": "4"},
    {"input": "Python nedir?", "expected": "programlama dili"},
]

# DeÄŸerlendir
results = evaluate(
    app.invoke,
    data=dataset,
    evaluators=[LangChainStringEvaluator("qa")],
    experiment_prefix="v1_test"
)
```

---

### 3. Prompt Hub

Prompt'larÄ±nÄ± LangSmith'te versiyonla ve takÄ±m arkadaÅŸlarÄ±nla paylaÅŸ:

```python
from langchain import hub

# Prompt'u Ã§ek (versiyonlu)
prompt = hub.pull("kullanici_adi/matematik-uzmani:v2")

# Kullan
chain = prompt | llm
```

Prompt deÄŸiÅŸikliÄŸi yaparken kodu deÄŸiÅŸtirmene gerek kalmaz â€” hub'dan gÃ¼ncelle.

---

### 4. Playground

LangSmith arayÃ¼zÃ¼nden herhangi bir geÃ§miÅŸ run'Ä± seÃ§ â†’ "Playground'da AÃ§" â†’ farklÄ± model/prompt dene â†’ karÅŸÄ±laÅŸtÄ±r.

---

## ğŸ“Œ Ã–zet Tablo

| Ã–zellik | Nerede? | Ne Ä°ÅŸe Yarar? |
|---------|---------|---------------|
| `Send` API | LangGraph | Paralel node Ã§alÄ±ÅŸtÄ±rma |
| Subgraph | LangGraph | Graf iÃ§inde alt graf |
| Human-in-the-Loop | LangGraph | Ä°nsan onayÄ± ile dur/devam |
| Streaming | LangGraph | AnlÄ±k token akÄ±ÅŸÄ± |
| Persistence | LangGraph | KonuÅŸma geÃ§miÅŸi, SQLite/Redis |
| LangGraph Studio | LangGraph CLI | GÃ¶rsel debug IDE |
| Tracing | LangSmith | Her Ã§aÄŸrÄ±yÄ± izle ve logla |
| Evaluator | LangSmith | Otomatik yanÄ±t kalitesi Ã¶lÃ§Ã¼mÃ¼ |
| Prompt Hub | LangSmith | Versiyonlu prompt yÃ¶netimi |
| Playground | LangSmith | Model/prompt karÅŸÄ±laÅŸtÄ±rma |

---

::: info Nereden Devam Edersin?
- [LangGraph DokÃ¼mantasyonu](https://langchain-ai.github.io/langgraph/)
- [LangSmith DokÃ¼mantasyonu](https://docs.smith.langchain.com/)
- [LangGraph Studio](https://studio.langchain.com/)
- [LangChain Cookbook](https://github.com/langchain-ai/langchain/tree/master/cookbook)
:::
